{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f3f6a73-fca8-49c4-9557-0d83de78e3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Simple UNet-like segmentation model for demonstration purposes\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleUNet, self).__init__()\n",
    "        # Encoder layers\n",
    "        self.enc_conv1 = nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "        self.enc_conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        # Decoder layers\n",
    "        self.dec_conv1 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.dec_conv2 = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoding path\n",
    "        x1 = F.relu(self.enc_conv1(x))  # Encoder feature map 1\n",
    "        x2 = self.pool(x1)\n",
    "        x3 = F.relu(self.enc_conv2(x2))  # Encoder feature map 2\n",
    "        x4 = self.pool(x3)\n",
    "        \n",
    "        # Decoding path\n",
    "        x5 = F.relu(self.dec_conv1(F.interpolate(x4, scale_factor=2, mode='nearest')))  # Decoder feature map 1\n",
    "        x6 = F.relu(self.dec_conv2(F.interpolate(x5, scale_factor=2, mode='nearest')))  # Decoder feature map 2\n",
    "        \n",
    "        return x6\n",
    "\n",
    "# Hook function to capture and save feature maps\n",
    "def save_feature_maps(module, input, output, layer_name, folder='layer_outputs', cmap='viridis'):\n",
    "    os.makedirs(folder, exist_ok=True)  # Create directory if it doesn't exist\n",
    "    # Assuming the output is a batch of feature maps, we take the first one\n",
    "    feature_map = output[0].detach().cpu().numpy()\n",
    "    \n",
    "    # Normalize each feature map for visibility (you can also use a different normalization)\n",
    "    feature_map = (feature_map - feature_map.min()) / (feature_map.max() - feature_map.min())\n",
    "    \n",
    "    # If the output has multiple channels, save each as a separate image\n",
    "    for i in range(feature_map.shape[0]):\n",
    "        plt.imshow(feature_map[i], cmap=cmap)\n",
    "        plt.axis('off')\n",
    "        filename = os.path.join(folder, f'{layer_name}_feature_map_{i}.png')\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "\n",
    "# Function to register hooks on encoder and decoder layers, and order the saving process\n",
    "def register_hooks(model):\n",
    "    hooks = []\n",
    "    \n",
    "    # Register hooks for encoder layers first, followed by decoder layers\n",
    "    encoder_layers = ['enc_conv1', 'enc_conv2']\n",
    "    decoder_layers = ['dec_conv1', 'dec_conv2']\n",
    "    \n",
    "    # Hook encoder layers first\n",
    "    for name, layer in model.named_modules():\n",
    "        if name in encoder_layers:\n",
    "            hook = layer.register_forward_hook(\n",
    "                lambda module, input, output, layer_name=name: save_feature_maps(module, input, output, layer_name)\n",
    "            )\n",
    "            hooks.append(hook)\n",
    "    \n",
    "    # Hook decoder layers next\n",
    "    for name, layer in model.named_modules():\n",
    "        if name in decoder_layers:\n",
    "            hook = layer.register_forward_hook(\n",
    "                lambda module, input, output, layer_name=name: save_feature_maps(module, input, output, layer_name)\n",
    "            )\n",
    "            hooks.append(hook)\n",
    "    \n",
    "    return hooks\n",
    "\n",
    "# Function to convert images to a video using OpenCV\n",
    "def create_video_from_images(image_folder, video_name='feature_maps_video.mp4', fps=2):\n",
    "    images = [img for img in sorted(os.listdir(image_folder)) if img.endswith(\".png\")]\n",
    "    frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "    for image in images:\n",
    "        video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "    video.release()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the model\n",
    "    model = SimpleUNet()\n",
    "    \n",
    "    # Register hooks to save feature maps at each layer (first encoder, then decoder)\n",
    "    hooks = register_hooks(model)\n",
    "    \n",
    "    # Load your own image\n",
    "    transform = transforms.Compose([transforms.Grayscale(), transforms.Resize((256, 256)), transforms.ToTensor()])\n",
    "    img = Image.open(\"test.jpg\")  # Replace with your image\n",
    "    input_image = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        output = model(input_image)\n",
    "    \n",
    "    # After forward pass, the feature maps will be saved as images in the folder 'layer_outputs'\n",
    "    \n",
    "    # Convert the saved images to a video\n",
    "    create_video_from_images('layer_outputs', video_name='feature_maps_video_1.mp4', fps=2)\n",
    "    \n",
    "    # Remove hooks after use\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baa28e9-0679-42c3-a1f7-60a751477dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
